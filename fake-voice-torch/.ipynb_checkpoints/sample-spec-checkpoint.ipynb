{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5641e1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n",
      "No module named 'foundations'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import model\n",
    "import torch\n",
    "\n",
    "from constants import model_params, base_data_path\n",
    "from IPython.display import Image \n",
    "from matplotlib.pyplot import imshow\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a303d24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0050faba196c967a.mp3', '0001986a7d172fe0.mp3']\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# see issue #152\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# Directory from which we read the data\n",
    "mode = \"unlabeled\"  # real, fake, or unlabeled\n",
    "\n",
    "# Convert files to flac\n",
    "# convert_to_flac(os.path.join(data_dir,mode))\n",
    "dirpath = '../datasets/train/audios-mp3'\n",
    "filenames = os.listdir(dirpath)\n",
    "# filenames = [f'{dirpath}/{filename}' for filename in filenames]\n",
    "filenames = filenames[:2]\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f587e13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0050faba196c967a.mp3\n"
     ]
    }
   ],
   "source": [
    "filename = filenames[0]\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c368fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CnnAudioNet(nn.Module):\n",
    "    def __init__(self, NumClasses=2):\n",
    "        super(CnnAudioNet,self).__init__()\n",
    "        self.NumClasses = NumClasses\n",
    "        self.Fc_features = 128\n",
    "        self.C1 = nn.Conv2d(1,32,5,padding=1)\n",
    "        self.C2 = nn.Conv2d(32,32,5,padding=1)\n",
    "        self.C3 = nn.Conv2d(32,64,5,padding=1)\n",
    "        self.C4 = nn.Conv2d(64,64,5,padding=1)\n",
    "        \n",
    "        self.BN1 = nn.BatchNorm2d(32)\n",
    "        self.BN2 = nn.BatchNorm2d(64)\n",
    "        self.BN3 = nn.BatchNorm2d(64)\n",
    "        self.maxpool1 = nn.MaxPool2d(2,2)\n",
    "        self.maxpool2 = nn.MaxPool2d((1,2),(1,2))\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(64*8*8,128)\n",
    "        self.fc2 = nn.Linear(128,self.NumClasses )\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.Bat1 = nn.BatchNorm1d(128)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = F.relu(self.BN1(self.C1(x)))\n",
    "        x = self.maxpool1(F.relu(self.BN1(self.C2(x))))\n",
    "        x = F.relu(self.BN2(self.C3(x)))\n",
    "        x = self.maxpool1(F.relu(self.BN2(self.C4(x))))\n",
    "        x = F.relu(self.BN2(self.C4(x)))\n",
    "        x = self.maxpool1(F.relu(self.BN2(self.C4(x))))\n",
    "        x = F.relu(self.BN2(self.C4(x)))\n",
    "        x = F.relu(self.BN3(self.C4(x)))\n",
    "        # flatten image input\n",
    "        x = self.dropout(x.view(-1,64*8*8))\n",
    "        # add dropout layer\n",
    "        x =  self.dropout(self.fc1(x))\n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        # add dropout layer\n",
    "        # add 2nd hidden layer, with relu activation function\n",
    "        #x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "audioNet = CnnAudioNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c883729d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.8312e-05,\n",
      "         -2.5749e-05, -2.5034e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.8312e-05,\n",
      "         -2.5749e-05, -2.5034e-05]]) 44100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milselarch/projects/AISG/venv/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IM torch.Size([128, 128])\n"
     ]
    }
   ],
   "source": [
    "# !pip install torchaudio\n",
    "import torchaudio\n",
    "\n",
    "path = os.path.join(dirpath, filename)\n",
    "sound, sample_rate = torchaudio.load(path)\n",
    "print(sound, sample_rate)\n",
    "data, fs =  librosa.load(path)\n",
    "\n",
    "data = np.float32(data)\n",
    "S = librosa.feature.melspectrogram(data, sr=sample_rate, n_mels=128)\n",
    "Mel = librosa.power_to_db(S, ref=np.max)/10+4\n",
    "# LabelOut = torch.from_numpy(self.labels[ID]).double()\n",
    "\n",
    "NFCC_Num = 128\n",
    "TimeSamp = 128\n",
    "Im = torch.zeros((NFCC_Num, TimeSamp)).type(torch.FloatTensor)\n",
    "Ssum = np.sum(Mel,axis=0)\n",
    "MaxE = np.argmax(Ssum)\n",
    "\n",
    "if MaxE > Mel.shape[1]-64 : \n",
    "    MaxE = Mel.shape[1]-65\n",
    "if MaxE< 64 :\n",
    "    MaxE = 64\n",
    "if Mel.shape[1] > TimeSamp :\n",
    "    Im = torch.from_numpy(Mel[:,MaxE-64:MaxE+64])\n",
    "else: \n",
    "    Im[:,:Mel.shape[1]  ] = torch.from_numpy(Mel)\n",
    "\n",
    "Im = Im.double()\n",
    "print('IM', Im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "631dfc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6107, -0.0216]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataBatch = Im.unsqueeze(0)\n",
    "dataBatch = dataBatch.unsqueeze(1).float()\n",
    "audioNet(dataBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d48510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
